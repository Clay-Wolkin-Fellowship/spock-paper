\newcommand{\SAMPN}{100}
\newcommand{\SAMPK}{2000000}
\newcommand{\SAMP}{1400000}
\newcommand{\WARM}{100000}
\newcommand{\COOL}{500000}
\newcommand{\comment}[1]{}

\section{Methodology}
We simulate a set associative cache using a number of different
replacement policies.
We use a statistical sampling technique to keep our total simulation
time down while still ensuring our results are representative of the
overall behavior for the application in question.

Mention PIN, NPB, Custom Python Cache Simulation

\subsection{Sampling Technique}
We sampled the file to minimize the data set we operated on, while maintaining the integrity with results.
	We took \SAMPN samples of \SAMPK memory access generated by sp\_omp instrumented by PIN.
	By the central limit theorem we can approximate samples of this size as having a gaussian distribution.
	Each sample was divided into 3 sections, a warm-up period of \WARM memory accesses,
		a sampling period of \SAMP memory accesses, and a cool-down period of \COOL memory accesses.
	For each metric we warmed up the cache during the warm-up period,
		then measured how long it took for any cache line evicted during the sampling period to be recached.
	Cache lines that took longer than the cool-down period to recache were ignored.
	We felt that cache lines that took more than \COOL memory accesses to recache were unlikely to be interesting.

\subsection{Caching Policies}

\subsubsection{Belady}
\subsubsection{FIFO}
\subsubsection{LRU}
\subsubsection{MRU}
\subsubsection{NRU FIFO}
\subsubsection{NRU Random}
\subsubsection{Random}
\subsubsection{SRRIP}
\subsubsection{DRRIP}
\subsubsection{BRRIP}


\label{sec:policies}
BELADY

NRU

DRRIP
