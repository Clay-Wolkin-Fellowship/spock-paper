\section{Analysis}

We chose sp\_omp because it showed an interesting distribution of Memory Accesses to Recache (MATR).
We have plotted several cache replacemant algorithms against Belady's Optimal Algorithm.
As you can see all cache algorithms have a lot of replacements under 100 K memory accesses from eviction.
However, there are 3 peaks 250 K, 300 K, and 350 K memory accesses, with similar peaks in the other replacement algorithms.
As expected MRU quickly recaches most of the evicted data.
More interesting is that SRRIP, LRU, and FIFO, have shifted the peak slightly earlier, meaning that they cache the results slightly longer than possible.
Meanwhile, RAND and NRU\_RAND spread out the peak more, which is expected given the inherent randomness in each of the algorthims.
DRRIP and BRRIP managed to determine roughly half the time that some of the lines are not going to be used for a long time and release them.
This shows the ability have DRRIP and BRRIP to determine quickly which memory locations are not going to be used in a long time,
 this is advantageous because it frees up cache lines for data which would be used sooner.

This visualization allows cache designers to understand more clearly if the algorithm is having its intended effect.
For instance as previously mentioned DRRIP and BRRIP both appear to split the difference between SRRIP and Belady.
This means that BRRIP's improvements are working in these cases, and BRRIP is more often able to determine when something will not be used for a long time.
However DRRIP looks very similar to BRRIP, although you would expect it to be able to move the rest of the peak over.
This is not the case, and clearly there is room to improve to be the same as belady.

In Figure~\ref{matr:buc:all}, we see an example of a TT graph.
Each of these graphs is a histrogram of TTR values.
The bins of a TTR graph, along the X-axis are periods of time that a cache block has been absent before returning.
The Y-axis of the graph is the number of cache blocks that were absent from the cache for that long before returning.
The intuition of how to read a TTR graph is as follows.
A high Y value is generally bad, because it means there were many evictions and recaches,
 however if Belady also has a high Y value, than this is a property of the program, and your caching policy cannot do better,
 (the program however could possibly be rewritten).
Many TTR graphs include humps in their distribution, humps that appear significantly later than any equivalent hump in Belady are bad,
 this means that you are holding onto data for too long.
Humps that do no appear at all in Belady, means that it would be optimal to hold the data long enough for the second recache to occur,
 in this case your caching policy does not hold onto data long enough.

For instance consider again Figure~\ref{matr:buc:all}, in this case we see 3 humps starting at about 250K memory accesses for each algorithm.
We can conclude that SRRIP is always holding onto too long since it's hump is about the same size as Belady's but earlier.
However, BRRIP and DRRIP, are able to correctly evict the cache block as early as belady half the time,
 and the other half the time they evict around the same time as SRRIP, resulting in two humps for each hump of belady.
As we would expect, random eviction spreads out the evictions, resulting in one very wide hump going between SRRIP and belady.

We can conclude from this graph that BRRIP and DRRIP are correctling predicting rereference intervals for some of the data, approximately half the time.
However, it is also clear that we can do better, as some cache blocks are incorrectly predicted under BRRIP and DRRIP.
Furthermore SRRIP is not correctly predicting the rereference interval at all for the memory accesses resulting in these humps.
